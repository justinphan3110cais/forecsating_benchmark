{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11362233986928105 0.8235294117647058 0.8954248366013072 153\n",
      "model\n",
      "acc: 82.35%\n",
      "brier: 0.1136 /  153\n",
      "crowd\n",
      "acc: 89.54%\n",
      "brier: 0.0838\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "avg_brier = []\n",
    "avg_acc = []\n",
    "# with open(f\"halawi_output/halawi_v15_metaculus_o1-preview_breadth7_run0.json\") as file:\n",
    "with open(\"public_output/test_metaculus_full_v17_o1-preview_chunk3_run0.json\") as file:\n",
    "    data= json.load(file)\n",
    "\n",
    "cors_crowd = []\n",
    "cors_model = []\n",
    "avg_scores = []\n",
    "crowd_scores = []\n",
    "for market in data:\n",
    "    # if market['data_source'] != 'metaculus': \n",
    "    #     continue\n",
    "    # if market['question_type'].lower() != 'binary':\n",
    "    #     continue\n",
    "\n",
    "    pred = market['predictions'][0]\n",
    "    # if \"2023\" in pred:\n",
    "    #     print(market['response'][0])\n",
    "    if pred == None:\n",
    "        continue\n",
    "        # pred = 0.0\n",
    "    # print(pred)\n",
    "    if pred > 2000:\n",
    "        continue\n",
    "    if pred > 1:\n",
    "        # print(pred)\n",
    "        pred = pred / 100\n",
    "    # if pred == None:\n",
    "    #     continue\n",
    "    crow_pred = market['crowd_pred'][3][-1]\n",
    "    resolution = market['resolution']\n",
    "\n",
    "    score = (pred - resolution) ** 2\n",
    "    crowd_score = (crow_pred - resolution) ** 2\n",
    "\n",
    "    cors_model.append(int(pred > 0.50) == resolution)\n",
    "    cors_crowd.append(int(crow_pred> 0.50) == resolution)\n",
    "    avg_scores.append(score)\n",
    "    crowd_scores.append(crowd_score)\n",
    "\n",
    "avg_brier.append(np.mean(avg_scores))\n",
    "avg_acc.append(np.mean(cors_model))\n",
    "print(np.mean(avg_scores), np.mean(cors_model), np.mean(cors_crowd), len(cors_model))\n",
    "\n",
    "print(\"model\")\n",
    "print(f\"acc: {np.mean(cors_model) * 100:.2f}%\")\n",
    "print(f\"brier: {np.mean(avg_scores):.4f} / \", len(avg_scores))\n",
    "\n",
    "print(\"crowd\")\n",
    "print(f\"acc: {np.mean(cors_crowd) * 100:.2f}%\")\n",
    "print(f\"brier: {np.mean(crowd_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: Will a debate be held between Joe Biden and Donald Trump before the 2024 US presidential election?\n",
      "model:  0.4  | score: 0.36\n",
      "crowd:  0.57  | score: 0.18490000000000004\n",
      "res= 1.0\n",
      "=====\n",
      "question: Will salvage operations commence on the cargo vessel \"M/V Rubymar\" prior to April 1, 2024?\n",
      "model:  0.65  | score: 0.42250000000000004\n",
      "crowd:  0.496  | score: 0.24601599999999998\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will UCLA hold its in-person, university-wide graduation commencement ceremonies on June 14, 2024?\n",
      "model:  0.45  | score: 0.30250000000000005\n",
      "crowd:  0.628  | score: 0.138384\n",
      "res= 1.0\n",
      "=====\n",
      "question: Will OpenAI investors file lawsuits against the OpenAI board related to the firing of Sam Altman before March 1, 2024?\n",
      "model:  0.6  | score: 0.36\n",
      "crowd:  0.215  | score: 0.046224999999999995\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will Leinier Domínguez Pérez be one of the 8 players to participate in the 2024 FIDE Candidates tournament?\n",
      "model:  0.6  | score: 0.36\n",
      "crowd:  0.056  | score: 0.0031360000000000003\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will the International Criminal Court issue arrest warrants for any of the listed Israeli leaders before July 1, 2024?\n",
      "model:  0.6  | score: 0.36\n",
      "crowd:  0.454  | score: 0.20611600000000002\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will Wesley So participate in the 2024 FIDE Candidates tournament?\n",
      "model:  0.7  | score: 0.48999999999999994\n",
      "crowd:  0.482  | score: 0.23232399999999997\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will at least 2 of the countries listed below be reinfected with either WPV1 or cVDPV by June 1, 2024?\n",
      "model:  0.1  | score: 0.81\n",
      "crowd:  0.616  | score: 0.147456\n",
      "res= 1.0\n",
      "=====\n",
      "question: Will Nvidia be one of the top four companies by market capitalization on March 29, 2024?\n",
      "model:  0.2  | score: 0.6400000000000001\n",
      "crowd:  0.858  | score: 0.020164000000000005\n",
      "res= 1.0\n",
      "=====\n",
      "question: Will the maximum weekly rate of hospitalizations per 100,000 in the US occur within four weeks of the combined peak for COVID, influenza, and RSV in the 2023-24 season?\n",
      "model:  0.3  | score: 0.48999999999999994\n",
      "crowd:  0.84  | score: 0.02560000000000001\n",
      "res= 1.0\n",
      "=====\n",
      "question: Will Rishi Sunak be elected in the 2024 UK General Election?\n",
      "model:  0.7  | score: 0.48999999999999994\n",
      "crowd:  0.289  | score: 0.08352099999999998\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will the Crimean Bridge be hit with an attack before July 1, 2024?\n",
      "model:  0.6  | score: 0.36\n",
      "crowd:  0.161  | score: 0.025921000000000003\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will Iran carry out a deadly attack in Israel before May 1, 2024?\n",
      "model:  0.7  | score: 0.48999999999999994\n",
      "crowd:  0.238  | score: 0.05664399999999999\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will the Pandemic Agreement be approved at the May 2024 World Health Assembly?\n",
      "model:  0.55  | score: 0.30250000000000005\n",
      "crowd:  0.463  | score: 0.21436900000000003\n",
      "res= 0.0\n",
      "=====\n",
      "question: Will Macky Sall step down as president of Senegal at or before the currently scheduled end of his term?\n",
      "model:  0.2  | score: 0.6400000000000001\n",
      "crowd:  0.689  | score: 0.09672100000000003\n",
      "res= 1.0\n",
      "=====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8954248366013072, 0.8235294117647058)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# with open(\"halawi_output/halawi_v15_metaculus_grok-2-latest_breadth7_run1_full.json\") as file:\n",
    "with open(\"public_output/test_metaculus_full_v17_o1-preview_chunk3_run0_full.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "cnt = 0\n",
    "hard_questions = []\n",
    "avg_scores = []\n",
    "\n",
    "chunk = 0\n",
    "cors_model = []\n",
    "cors_crowd = []\n",
    "for market in data:\n",
    "    # if market['data_source'] != 'metaculus': \n",
    "    #     continue\n",
    "    \n",
    "    pred = market['predictions'][0]\n",
    "    if pred == None:\n",
    "        continue\n",
    "    crow_pred = market['crowd_pred'][3][-1]\n",
    "    origin_crowd_pred = market['crowd_pred'][0][-1]\n",
    "    resolution = market['resolution']\n",
    "    \n",
    "\n",
    "    model_score = (pred - resolution) ** 2\n",
    "\n",
    "    crowd_score = (crow_pred - resolution) ** 2\n",
    "    og_crowd_score = (origin_crowd_pred - resolution) ** 2\n",
    "    cor_model = int(pred > .50) == resolution\n",
    "    cor_crowd = int(crow_pred >.50) == resolution\n",
    "    cors_model.append(cor_model)\n",
    "    cors_crowd.append(cor_crowd)\n",
    "    avg_scores.append(model_score)\n",
    "    if len(market['sources'][0]) == 0:\n",
    "        cnt += 1\n",
    "    # if model_score - crowd_score > 0.1:\n",
    "    if not cor_model and cor_crowd:\n",
    "        question = market['question']\n",
    "        hard_questions.append(market)\n",
    "        print(\"question:\", question)\n",
    "        print(\"model: \", pred, \" | score:\", model_score)\n",
    "        print(\"crowd: \", crow_pred, \" | score:\", crowd_score)\n",
    "        print(\"res=\", resolution)\n",
    "        print(\"=====\")\n",
    "\n",
    "np.mean(cors_crowd), np.mean(cors_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_cors_model= ['62.86%', '74.29%', '82.86%', '77.14%', '80.00%']\n",
      "all_cors_crowd= ['77.14%', '71.43%', '77.14%', '82.86%', '88.57%']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "avg_brier = []\n",
    "avg_acc = []\n",
    "\n",
    "file_name = \"halawi_v15_metaculus_0_full.json\"\n",
    "file_name = \"halawi_v15_metaculus_grok-2-latest_breadth10_run0.json\"\n",
    "\n",
    "\n",
    "# file_name = \"halawi_v15_metaculus_breadth7.json\"\n",
    "# file_name = \"halawi_v15_0.json\"\n",
    "with open(f\"halawi_output/{file_name}\") as file:\n",
    "    data= json.load(file)\n",
    "\n",
    "all_cors_model = []\n",
    "all_cors_crowd = []\n",
    "for chunk in range(0,5):\n",
    "    cors_crowd = []\n",
    "    cors_model = []\n",
    "    avg_scores = []\n",
    "    crowd_scores = []\n",
    "    for market in data:\n",
    "        # if market['data_source'] != 'metaculus': \n",
    "        #     continue\n",
    "        # if market['question_type'].lower() != 'binary':\n",
    "        #     continue\n",
    "        \n",
    "        # print(\"market['predictions']=\",market['predictions'])\n",
    "        pred = market['predictions'][chunk]\n",
    "        # assert pred\n",
    "        crow_pred = market['crowd_pred'][chunk][-1]\n",
    "        resolution = market['resolution']\n",
    "\n",
    "        score = (pred - resolution) ** 2\n",
    "        crowd_score = (crow_pred - resolution) ** 2\n",
    "\n",
    "        cors_model.append(int(pred > 0.50) == resolution)\n",
    "        cors_crowd.append(int(crow_pred> 0.50) == resolution)\n",
    "        avg_scores.append(score)\n",
    "        crowd_scores.append(crowd_score)\n",
    "\n",
    "    avg_brier.append(np.mean(avg_scores))\n",
    "    avg_acc.append(np.mean(cors_model))\n",
    "    # print(np.mean(avg_scores), np.mean(cors_model), np.mean(cors_crowd), len(cors_model))\n",
    "\n",
    "    all_cors_model.append(f\"{np.mean(cors_model) * 100:.2f}%\")\n",
    "    all_cors_crowd.append(f\"{np.mean(cors_crowd) * 100:.2f}%\")\n",
    "    # print(\"model\")\n",
    "    # print(f\"acc: {np.mean(cors_model) * 100:.2f}%\")\n",
    "    # print(f\"brier: {np.mean(avg_scores):.4f} / \", len(avg_scores))\n",
    "\n",
    "    # print(\"crowd\")\n",
    "    # print(f\"acc: {np.mean(cors_crowd) * 100:.2f}%\")\n",
    "    # print(f\"brier: {np.mean(crowd_scores):.4f}\")\n",
    "\n",
    "print(\"all_cors_model=\",all_cors_model)\n",
    "print(\"all_cors_crowd=\",all_cors_crowd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_prediction_durations(data):\n",
    "    durations = []\n",
    "\n",
    "    for question in data:\n",
    "        crowd_pred = question['crowd_pred']\n",
    "        first_prediction = datetime.strptime(crowd_pred[0][1], \"%Y-%m-%d\")\n",
    "        last_prediction = datetime.strptime(crowd_pred[-1][1], \"%Y-%m-%d\")\n",
    "        duration = (last_prediction - first_prediction).days\n",
    "        durations.append(duration)\n",
    "\n",
    "    average_duration = sum(durations) / len(durations)\n",
    "    return average_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results:\n",
      "Chunk 0:Acc 73.71% ± 4.24% | Brier: 0.1736 ± 0.0163\n",
      "Chunk 1:Acc 80.00% ± 5.35% | Brier: 0.1746 ± 0.0660\n",
      "Chunk 2:Acc 88.47% ± 5.28% | Brier: 0.0936 ± 0.0350\n",
      "Chunk 3:Acc 86.29% ± 2.39% | Brier: 0.1031 ± 0.0155\n",
      "Chunk 4:Acc 90.29% ± 4.78% | Brier: 0.0826 ± 0.0310\n",
      "avg: 83.75064935064935 ±  4.475717358837765\n",
      "\n",
      "Crowd Results:\n",
      "Chunk 0: 77.14% ± 0.00% | Brier: 0.1704 ± 0.0000\n",
      "Chunk 1: 71.43% ± 0.00% | Brier: 0.1375 ± 0.0000\n",
      "Chunk 2: 77.47% ± 0.74% | Brier: 0.1196 ± 0.0057\n",
      "Chunk 3: 82.86% ± 0.00% | Brier: 0.1062 ± 0.0000\n",
      "Chunk 4: 88.57% ± 0.00% | Brier: 0.0723 ± 0.0000\n",
      "avg: 79.4943722943723\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def process_file(file_name):\n",
    "    with open(f\"halawi_output/{file_name}\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    all_cors_model = []\n",
    "    all_cors_crowd = []\n",
    "    all_scores_model = []\n",
    "    all_scores_crowd = []\n",
    "    for chunk in range(0, 5):\n",
    "        cors_model = []\n",
    "        cors_crowd = []\n",
    "\n",
    "        scores_model = []\n",
    "        scores_crowd = []        \n",
    "        for market in data:\n",
    "            question = market['question']\n",
    "            # if question_to_num_forecast[question] < 20:\n",
    "            #     print(\"question_to_num_forecast=\",question_to_num_forecast[question])\n",
    "            #     continue\n",
    "            \n",
    "            pred = market['predictions'][chunk]\n",
    "            if pred == None:\n",
    "                continue\n",
    "            if pred > 100:\n",
    "                pred = -1\n",
    "            if pred > 1:\n",
    "                pred = pred / 100\n",
    "            crow_pred = market['crowd_pred'][chunk][-1]\n",
    "            resolution = market['resolution']\n",
    "            \n",
    "            cors_model.append(int(pred > 0.50) == resolution)\n",
    "            cors_crowd.append(int(crow_pred > 0.50) == resolution)\n",
    "\n",
    "            scores_model.append((pred - resolution) ** 2)\n",
    "            scores_crowd.append((crow_pred - resolution) ** 2)\n",
    "        \n",
    "        total_date = calculate_prediction_durations(data)\n",
    "\n",
    "        all_cors_model.append(np.mean(cors_model) * 100)\n",
    "        all_cors_crowd.append(np.mean(cors_crowd) * 100)\n",
    "        all_scores_model.append(np.mean(scores_model))\n",
    "        all_scores_crowd.append(np.mean(scores_crowd))\n",
    "    \n",
    "    return all_cors_model, all_cors_crowd, all_scores_model, all_scores_crowd, total_date\n",
    "\n",
    "# Process all files\n",
    "results = []\n",
    "for run in range(5):\n",
    "# for run in (0,0):\n",
    "    # file_name = f\"halawi_v15_metaculus_full_breadth7_run{run}.json\"\n",
    "    # file_name = f\"halawi_v15_metaculus_grok-2-latest_breadth7_run{run}.json\"\n",
    "    file_name = f\"halawi_v15_metaculus_o1-preview_breadth7_run{run}.json\"\n",
    "    # file_name = f\"halawi_v16_metaculus_gpt-4o-2024-05-13_breadth7_run{run}.json\"\n",
    "    results.append(process_file(file_name))\n",
    "\n",
    "# Separate model and crowd results\n",
    "model_results = [result[0] for result in results]\n",
    "model_scores = [result[2] for result in results]\n",
    "\n",
    "crowd_results = [result[1] for result in results]\n",
    "crowd_scores = [result[3] for result in results]\n",
    "total_date = [result[-1] for result in results]\n",
    "\n",
    "# Calculate averages and standard deviations\n",
    "model_averages = [mean(chunk) for chunk in zip(*model_results)]\n",
    "model_stdevs = [stdev(chunk) for chunk in zip(*model_results)]\n",
    "model_scores_averages = [mean(chunk) for chunk in zip(*model_scores)]\n",
    "model_scores_std =  [stdev(chunk) for chunk in zip(*model_scores)]\n",
    "\n",
    "\n",
    "crowd_averages = [mean(chunk) for chunk in zip(*crowd_results)]\n",
    "crowd_stdevs = [stdev(chunk) for chunk in zip(*crowd_results)]\n",
    "crowd_scores_averages = [mean(chunk) for chunk in zip(*crowd_scores)]\n",
    "crowd_scores_std = [stdev(chunk) for chunk in zip(*crowd_scores)]\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Model Results:\")\n",
    "for i, (avg, std) in enumerate(zip(model_averages, model_stdevs)):\n",
    "    print(f\"Chunk {i}:Acc {avg:.2f}% ± {std:.2f}% | Brier: {model_scores_averages[i]:.4f} ± {model_scores_std[i]:.4f}\")\n",
    "\n",
    "model_stdevs_squared = [std**2 for std in model_stdevs[:-1]]\n",
    "model_overall_std = np.sqrt(np.mean(model_stdevs_squared))\n",
    "print(\"avg:\", np.mean(model_averages), \"± \", np.mean(model_overall_std))\n",
    "\n",
    "print(\"\\nCrowd Results:\")\n",
    "for i, (avg, std) in enumerate(zip(crowd_averages, crowd_stdevs)):\n",
    "    print(f\"Chunk {i}: {avg:.2f}% ± {std:.2f}% | Brier: {crowd_scores_averages[i]:.4f} ± {crowd_scores_std[i]:.4f}\")\n",
    "\n",
    "print(\"avg:\", np.mean(crowd_averages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 00:00:00 2023-12-01 00:00:00\n",
      "Will Erling Haaland score the most goals in the 2023/24 Premier League season?\n",
      "===\n",
      "2023-11-30 00:00:00 2023-12-01 00:00:00\n",
      "Will Ursula von der Leyen be re-appointed as President of the European Commission following the 2024 European elections?\n",
      "===\n",
      "2023-11-12 00:00:00 2023-12-01 00:00:00\n",
      "Will the UK and India have signed an FTA before the next UK General Election?\n",
      "===\n",
      "2023-10-24 00:00:00 2023-12-01 00:00:00\n",
      "Will ChatGPT be available in Europe on June 30, 2024?\n",
      "===\n",
      "2023-11-12 00:00:00 2023-12-01 00:00:00\n",
      "Will the right-wing incumbent BJP win the 2024 national election in India?\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106.51412429378531, 0, 310)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/data/long_phan/forecasting_platform/backend/src/benchmarks/data/metaculus_sample_full.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "durations = []\n",
    "\n",
    "for question in data:\n",
    "    crowd_pred = question['crowd_pred']\n",
    "    first_prediction = datetime.strptime(crowd_pred[0][1], \"%Y-%m-%d\")\n",
    "    last_prediction = datetime.strptime(crowd_pred[-1][1], \"%Y-%m-%d\")\n",
    "    \n",
    "    third_time = datetime.strptime(crowd_pred[3][1], \"%Y-%m-%d\")\n",
    "    cut_off = datetime.strptime(\"2023-12-01\", \"%Y-%m-%d\")\n",
    "    if third_time < cut_off:\n",
    "        print(third_time, cut_off)\n",
    "        print(question['question'])\n",
    "        print(\"===\")\n",
    "\n",
    "    duration = (last_prediction - first_prediction).days\n",
    "    # if duration < 7:\n",
    "    #     print(question['question'])\n",
    "    #     continue\n",
    "    durations.append(duration)\n",
    "\n",
    "average_duration = mean(durations)\n",
    "average_duration, min(durations), max(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 241/914 [00:00<00:01, 671.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_forecasters= 100\n",
      "number_of_forecasters= 112\n",
      "number_of_forecasters= 83\n",
      "number_of_forecasters= 39\n",
      "number_of_forecasters= 45\n",
      "number_of_forecasters= 18\n",
      "number_of_forecasters= 178\n",
      "number_of_forecasters= 61\n",
      "number_of_forecasters= 58\n",
      "number_of_forecasters= 70\n",
      "number_of_forecasters= 53\n",
      "number_of_forecasters= 56\n",
      "number_of_forecasters= 53\n",
      "number_of_forecasters= 50\n",
      "number_of_forecasters= 92\n",
      "number_of_forecasters= 8\n",
      "number_of_forecasters= 58\n",
      "number_of_forecasters= 32\n",
      "number_of_forecasters= 32\n",
      "number_of_forecasters= 32\n",
      "number_of_forecasters= 91\n",
      "number_of_forecasters= 73\n",
      "number_of_forecasters= 100\n",
      "number_of_forecasters= 47\n",
      "number_of_forecasters= 62\n",
      "number_of_forecasters= 38\n",
      "number_of_forecasters= 9\n",
      "number_of_forecasters= 27\n",
      "number_of_forecasters= 65\n",
      "number_of_forecasters= 80\n",
      "number_of_forecasters= 58\n",
      "number_of_forecasters= 9\n",
      "number_of_forecasters= 59\n",
      "number_of_forecasters= 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 914/914 [00:11<00:00, 79.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_forecasters= 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"/data/long_phan/forecasting_platform/backend/src/benchmarks/data/halawi_dataset_metaculus_full.json\") as file:\n",
    "    anchor_data = {}\n",
    "    for d in json.load(file):\n",
    "        anchor_data[d['question']] = d\n",
    "\n",
    "# Load both test and validation splits\n",
    "dataset = load_dataset(\"YuehHanChen/forecasting\", split=\"test\")\n",
    "question_to_num_forecast = {}\n",
    "for row in tqdm(dataset):\n",
    "    question = row['question']\n",
    "    if question in anchor_data:\n",
    "        try:\n",
    "            response = requests.get(row['url']).json()\n",
    "            number_of_forecasters = response['number_of_forecasters']\n",
    "            print(\"number_of_forecasters=\",number_of_forecasters)\n",
    "            question_to_num_forecast[question] = number_of_forecasters\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_to_num_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.924242424242424, 4, 28)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/data/long_phan/forecasting_platform/backend/src/benchmarks/data/halawi_dataset_polymarket.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "durations = []\n",
    "\n",
    "for question in data:\n",
    "    crowd_pred = question['crowd_pred']\n",
    "    first_prediction = datetime.strptime(crowd_pred[0][1], \"%Y-%m-%d\")\n",
    "    last_prediction = datetime.strptime(crowd_pred[-1][1], \"%Y-%m-%d\")\n",
    "    \n",
    "    third_time = datetime.strptime(crowd_pred[3][1], \"%Y-%m-%d\")\n",
    "    cut_off = datetime.strptime(\"2023-12-01\", \"%Y-%m-%d\")\n",
    "    # if third_time < cut_off:\n",
    "    #     print(third_time, cut_off)\n",
    "    #     print(question['question'])\n",
    "    #     print(\"===\")\n",
    "\n",
    "    duration = (last_prediction - first_prediction).days\n",
    "    # if duration < 7:\n",
    "    #     print(question['question'])\n",
    "    #     continue\n",
    "    durations.append(duration)\n",
    "\n",
    "average_duration = mean(durations)\n",
    "average_duration, min(durations), max(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Results:\n",
    "Chunk 0: 68.57% ± 0.00%\n",
    "Chunk 1: 69.52% ± 1.65%\n",
    "Chunk 2: 75.24% ± 1.65%\n",
    "Chunk 3: 82.86% ± 4.95%\n",
    "Chunk 4: 80.95% ± 3.30%\n",
    "\n",
    "Crowd Results:\n",
    "Chunk 0: 77.14% ± 0.00%\n",
    "Chunk 1: 71.43% ± 0.00%\n",
    "Chunk 2: 77.14% ± 0.00%\n",
    "Chunk 3: 82.86% ± 0.00%\n",
    "Chunk 4: 88.57% ± 0.00%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
